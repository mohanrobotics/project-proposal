% \documentclass[rnd]{mas_proposal}
\documentclass[thesis]{mas_proposal}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{natbib} 

\title{Black-Box Optimization of Object Detector Hyper-Parameters}
\author{Mohandass Muthuraja}
\supervisors{Prof. Dr. Paul PlÌˆoger\\Second Supervisor \\ Dr. Matias Valdenegor-Toro}
\date{Month 20XX}

% \thirdpartylogo{path/to/your/image}

\begin{document}

\maketitle

\pagestyle{plain}

\section{Introduction}
Object detection deals with classifying and localizing objects of interest in a given image or frame. In recent years, a great deal of research is done in object detection. It has various use cases such as autonomous cars, anomaly detection, medical image analysis, video surveillance and the list goes on. Recent advances in the deep learning architectures, mainly Convolutional Neural Networks (CNN) and the advent of parallel computing through Graphical Processing Units(GPU) has taken object detection a step forward. Deep learning-based object detection methods have proved to perform way better than traditional detection methods that use handcrafted features(such as SIFT\cite{lowe2004distinctive}, HoG\cite{dalal2005histograms}, etc.)\cite{zou2019object}. The ability of CNN architectures (such as VGG\cite{simonyan2014very}, Inception\cite{szegedy2015going}, DenseNet\cite{huang2017densely}, ResNet\cite{he2016deep} etc.,) to represent the high-level features of the image is one of the reasons for the remarkable performance of the state-of-the-art object detectors. These CNN architectures form the backbone of most state-of-the-art object detectors. Along with the CNN architectures, the region proposal network-based object detectors like Faster R-CNN\cite{ren2015faster}, R-FCN\cite{dai2016r} and  Mask R-CNN\cite{he2017mask} achieved extraordinary detection results. Moreover, object detectors like YOLO\cite{redmon2016you}, SSD\cite{liu2016ssd} and YOLOv2\cite{redmon2017yolo9000}  have proved to achieve remarkable results despite taking fewer computations\cite{zhao2019object}. 

However, the performance of any deep learning algorithm depends heavily on the selection of various hyper-parameters that guide and controls the learning process. Each object detector has several hyper-parameters like image re-sizer dimensions, size and scales of prior/anchor boxes, Intersection Over Union (IOU) threshold, number of proposals in addition to the conventional deep learning hyper-parameters like learning rate, momentum and decay rate. The right choice of hyper-parameters here is essential as it plays a significant role in the model's performance. This task of hyper-parameter tuning is challenging as one need to choose the right hyper-parameter from the hyper-parameter search space efficiently. Machine learning experts and data scientists have intellectual depth and insight on setting hyper-parameters. Also, the experts conduct many experiments and choose hyper-parameters after many trial and errors. Besides, the hyper-parameters are dataset dependent as the hyper-parameters which works fine for one dataset may not perform better with another dataset\cite{automl_book}.

The tremendous growth of machine learning has created a need for automating this tedious process by avoiding human intervention. Automated machine learning (AutoML) is a newly emerging field which aims to automate the entire machine learning process. It includes automation of complete training pipeline right from data preprocessing, algorithm selection till setting the right hyper-parameters to obtain a obtain optimal performance\cite{automl_book}. Besides AutoML, black-box optimization methods can also be applied for the task of hyper-parameter optimization. Recent technical advancements in black-box optimization methods(such as Bayesian optimization, Genetic/Evolutionary algorithms) is getting more focused on hyper-parameter optimization. In this study, we will study AutoMl and black-box optimization methods for the task of setting hyper-parameters of object detectors on different datasets.
The main objectives of this study are as follows: 
\begin{itemize}
    \item A comprehensive literature study on the combined object detection and black-box optimization research fields.
    \item Defining the hyper-parameter search space of the state of the art deep convolutional object detectors.
    \item Comprehensive evaluation and comparison of  AutoMl and black-box optimization methods for hyper-parameter optimization specific to the state of the art object detectors on different datasets.
\end{itemize}
% \begin{itemize}
%     \item An introduction to the general topic you are covering.
%     \begin{itemize}
%     \item 3-4 sentences on object detection and CNNs in object detection
    
%     \item 3-4 sentences on importance of deep learning hyper parameters and object detection hyper parameters
%     \item 2-3 sentences on how experts decide the hyper parameters
%     \item 3-4 sentences on Auto Ml in the recent study
%     \item 3-4 general sentences on black box optimizer on deciding the hyper parameters
%     \item 3-4 sentences explaining what this project is about.
%     \end{itemize}
%     \item Why is it important?
    
% \end{itemize}

\subsection{Problem Statement}
In the last decade, there was a breakthrough in one of the most challenging computer vision task of object detection. Classical object detectors that use handcrafted features are not able to meet the performance of the deep learning-based modern-day object detectors\cite{zou2019object}. The state of the art object detectors were able to achieve excellent performance on the MS-COCO\cite{lin2014microsoft} and PASCAL VOC\cite{Everingham10} benchmark datasets. The main challenge in achieving robust performance using these object detectors is the setting of hyper-parameters as they are heavily dataset dependent and requires experts' knowledge. The right choice of hyper-parameter selection from the over-all hyper-parameter space undergoes a lot of trial and error after conducting several experiments. Also, the diversity of the hyper-parameters turns out to be even more problematic in the task of hyper-parameter optimization because they can be binary, categorical(e.g. activation function), continuous(e.g. learning rates, drop-out probability),  and conditional(e.g. Adam's second momentum is active only when the optimizer is Adam)\cite{automl_book}.  The hyper-parameter space of the deep learning-based object detectors is also many in numbers as every object detector has its own hyper-parameters like re-sizer dimensions, size and scales of prior/anchor boxes, Intersection Over Union (IOU) threshold, number of proposals etc., The approach to solve this problem involves the use of hyper-parameter optimization methods after defining the hyper-parameter space of the object detectors. Most basic hyper-parameter optimization methods use grid search\cite{montgomery2001design} and random search\cite{bergstra2012random} to select the set of hyper-parameters to obtain better performance. However, both these searches take a considerable amount of time and are computationally expensive. A guided search can reduce the computational complexity and time taken to find the right set of parameters.  
AutoML and Black-box optimization techniques have been applied to image classification successfully for neural architecture search and hyper-parameter optimization. Using AutoML and Black-box optimization techniques for object detection is a new open research topic which is gaining more importance among the researchers in the computer vision community. This proposed research work intends to study the applicability of the modern hyper-parameter optimization methods of AutoML and Black-box optimization. These methods will be used to tune the hyper-parameter particular to the deep-learning-based state of the art object detectors to achieve the optimal performance.  The hyper-parameter optimization task will be evaluated on a variety of datasets. Also, the idea is to guide the tuning process to balance the trade-off between high object detection performance and fewer computations.
% \begin{itemize}
%     \item What are you going to solve?
%     \begin{itemize}
%         \item Problems with random and grid search, Computational complexity , deciding the hyper parameters
%         \item How this can be solved using BBO
%     \end{itemize}
%     \item How are you evaluating?
% \end{itemize}


\section{Related Work}
% \begin{itemize}
%     \item What have other people done?
%     \begin{itemize}
%         \item Literature on SOTA object detection models
        
%         \item Literature on BBO techniques
%     \end{itemize}
%     \item Why is it not sufficient?
% \end{itemize}

\subsection{Object Detection}
Deep learning-based object detectors can be grouped into two types, namely, multi-stage detectors and single-stage detectors. Multi-stage detectors initially involve the selection of regions of interest(ROI) from an image and then detecting the class on those regions. In spite of obtaining remarkable results, multi-stage detectors need more computations. Single-stage detectors are faster than the multi-stage detectors as it does a combined task of locating and then classifying the objects in the image. 

\subsubsection{Multi-stage Detectors}

\textbf{R-CNN} by \citet{girshick2014rich} provided a breakthrough in 2014 by achieving 30\% better performance on the Pascal-VOC 2012 dataset. RCNN has three main steps. First, selective search algorithm was used to generate around 2000 regions on the image. Next, CNN's were used to extract a 4096-dimensional feature vector from those regions. Finally, the extracted features were classified using SVMs. 

\textbf{Fast R-CNN} by \citet{girshick2015fast} sorted out the issues in R-CNN by an alternative approach. First, instead of region proposals, the entire image was fed into CNN's to get a convolutional feature map. Then, the region proposals were determined on the convolutional feature map. Finally, the region proposals that were reshaped by ROI pooling layer were fed into a fully connected layer for classifying the objects. Fast R-CNN is faster because the convolution operation is done only once on the entire image instead of 2000 regions as in the case of R-CNN. 

\textbf{Faster R-CNN} by \citet{ren2015faster} introduced a Region Proposal Network(RPN) for identifying the region proposals which replaced the selective search algorithm in R-CNN and Fast R-CNN. The use of RPN instead of selective search algorithm proves to be more time-efficient and also has a better performance. In, Faster R-CNN, first, the image is fed into CNN's to produce a  convolutional feature map. Then the RPN provides region proposal from the convolutional feature map. Same like Fast R-CNN, these region proposals were reshaped by ROI pooling layer were fed into a fully connected layer for classifying the objects.

\subsubsection{Single stage Detectors}
\citet{redmon2016you} introduced a fast and accurate object detector called \textbf{YOLO}(You Look Only Once). Unlike the other multi-stage object detectors, YOLO considers object detection as a regression problem to determine the bounding box coordinates of the objects in the image and their corresponding class probabilities. YOLO uses a single neural network to perform the complete object detection. First, YOLO transforms the image into a grid of specific size. Then, in each grid, it considers bounding boxes and the network is trained to determine the bounding box offsets and the class probabilities. YOLO finds its use in applications which involve real-time predictions as it can predict 45 frames per second. The inadequacy of YOLO is that it is not good with smaller objects. To improve the accuracy and to balance the speed-accuracy trade-off, further improvements were made on its successive version YOLO v2 \cite{redmon2017yolo9000}. 

Single ShotMultiBox Detector (\textbf{SSD})  proposed by \citet{liu2016ssd} is another single stage object detector. SSD can overcome the deficit of YOLO as it performs well with smaller objects also. The vital feature of SSD is the multi-scale convolutional bounding box. Instead of the fixed grids in YOLO, SSD initially 'discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location.'\cite{liu2016ssd} Despite being three times faster, SSD512 model performs better than faster R-CNN on PASCAL VOC and COCO datasets. 

\textbf{RetinaNet} proposed by \citet{lin2017focal} addresses the foreground-background class imbalance issue in the previous object detectors. RetinaNet has a particular loss function called 'focal loss' loss function. This helps the single-stage detectors to achieve competitive results with the multi-stage detectors by not compromising the speed.  

\subsection{Subsection 1}
\subsection{Subsection 2}



\section{Project Plan}

\subsection{Work Packages}
The bare minimum will include the following packages:
\begin{enumerate}
    \item[WP1] Literature Search
    \item[WP2] Experiments
    \item[WP3] Project Report
\end{enumerate}
Keep in mind that depending on your project, you will probably need to add work packages that are more suited to your projects.

\subsection{Milestones}
\begin{enumerate}
    \item[M1] Literature search
    \item[M2] Experimental setup
    \item[M3] Experimental Analysis
    \item[M4] Report submission
\end{enumerate}

\subsection{Project Schedule}
Include a gantt chart here. It doesn't have to be detailed, but it should include the milestones you mentioned above.
Make sure to include the writing of your report throughout the whole project, not just at the end.

\begin{figure}[h!]
    \caption{}
    \includegraphics[width=\textwidth]{images/rnd_deliverable_timeline}
    \label{}
\end{figure}

\subsection{Deliverables}
\subsubsection*{Minimum Viable}

% \begin{itemize}
%     \item Survey
%     \item Analysis of state of the art
%     \item Simple simulated use case
%     \item Demo on youBot or Jenny
% \end{itemize}
\begin{itemize}
    \item Literature search and state of the art analysis on the  combined object detection and black-box optimization  fields.

\end{itemize}

\subsubsection*{Expected}
\begin{itemize}
    \item Appropriate experimental design to address the selected research questions.
    \item Comprehensive evaluation and comparison with the state of the art on the COCO and PASCAL VOC datasets on at least two object detectors.
\end{itemize}

\subsubsection*{Desired}
\begin{itemize}
    \item  Conference or journal paper describing the results from the Thesis
\end{itemize}


\nocite{*}

\bibliographystyle{plainnat} % Use the plainnat bibliography style
\bibliography{bibliography.bib} % Use the bibliography.bib file as the source of references




\end{document}
